\chapter{Methods}

The Correlated Gaussian Method is a variational method, which has been used to solve quantum-mechanical few-body problems in molecular, atomic and nuclear physics. The method has attained its popularity from the ease of calculating matrix elements in a Gaussian basis. Many matrix elements and their corresponding gradients are fully analytic, whereby numerical optimizations can be carried out with a high degree accuracy.


\section{Fully Correlated Gaussian Method}
The standard procedure when employing the correlated Gaussian method is utilizing "isotropic" Gaussians, which do not distinguish between directions for the individual particles. This approach is very efficient, as only few optimization parameters are needed. The lack of explicit directional bias is compensated by shifting the positions of the Gaussians, thus enabling accurate approximations of most wavefunctions. However, this approach is not feasible in squeezing problems, since the size of the Gaussians is limited by the width of any confining potential. As the potential is squeezed tightly in one direction, the number of isotropic Gaussians needed to cover the entire wavefunction will increase exponentially.
Hence, an alternative method is presented here, where fully correlated Gaussians are employed, which do distinguish directions at the cost of additional variational parameters. 
For a system of $N$ particles with coordinates $\boldsymbol{r} = (\vec{r}_1 , \vec{r}_2 , \ldots , \vec{r}_N)^{\mathrm{T}} = (r_1 , r_2 , \ldots , r_{3 N})^{\mathrm{T}}$, the fully correlated Gaussians have the form
\begin{align}
 \braket{ \boldsymbol{r} | g }  &\equiv  \exp \left( - \sum_{i < j = 1}^{3 \cdot N} a_{ij} (r_i - r_j)^2 + \sum_{i=1}^{3 \cdot N} s_i \cdot r_i \right)  \nonumber \\
  &=   \exp \left( - \sum_{i < j = 1}^{3 \cdot N} a_{ij} \boldsymbol{r}^{\mathrm{T}} w_{ij} w_{ij}^{\mathrm{T}} \boldsymbol{r} + \sum_{i=1}^{3 \cdot N} s_i \cdot r_i \right) \nonumber \\
 &=  e^{-\boldsymbol{r}^{\mathrm{T}} A \boldsymbol{r} + \boldsymbol{s}^{\mathrm{T}} \boldsymbol{r} } \; ,
\end{align}
where $\boldsymbol{s}$ is a column of variational shifts, $A$ is a positive-definite matrix containing the variational parameters $a_{ij} > 0$, and $w_{ij}$ is a size $3 N$ column vector of zeros with the exception of elements $i$ and $j$ being 1 and -1 respectively. 
This particular form is chosen ensure the positive-definiteness of $A$, as the matrix is constructed as a sum of positive-definite rank-1 matrices $a_{ij}  w_{ij} w_{ij}^{\mathrm{T}}$. 
The trial wavefunction of the few-body wavefunction, $\ket{\psi}$, is written as a linear combination of $K$ Gaussians
\begin{equation}
	\ket{\psi} = \sum_{i = 1}^{K} c_i \ket{g_i}
\end{equation}
Inserting this expression into the Schr\oe dinger equation
\begin{equation}
	\hat{H} \sum_{i=1}^{K} c_{i} \ket{g_i} = E \sum_{i=1}^{K} c_{i} \ket{g_i} 
\end{equation}
and multiplying from the left with $\bra{g_j}$ yields
\begin{equation}
	\sum_{i=1}^{K} c_{i} \bra{g_j} \hat{H} \ket{g_i} = E \sum_{i=1}^{K} c_{i} \braket{g_j | g_i} \; .
\end{equation}
This expression can be formulated as a generalized eigenvalue problem
\begin{equation}
	\mathcal{H} \boldsymbol{c} = E \mathcal{B} \boldsymbol{c} \; ,
	\label{eq:genEigenProb}
\end{equation}
where $\boldsymbol{c}$ is the column of linear parameters, $c_i$, while $\mathcal{H}_{j,i} \equiv \bra{g_j} \hat{H} \ket{g_i}$ and $\mathcal{B}_{j,i} \equiv \braket{g_j | g_i}$. A downside of utilizing a basis of Gaussians is the non-orthogonality of the functions resulting in a non-identity overlap-matrix, $\mathcal{B}$. The generalized eigenvalue problem can be turned into a regular eigenvalue problem through a Cholesky decomposition, and the symmetry of the matrices $\mathcal{H}$ and $\mathcal{B}$ can be exploited for obtaining solutions faster. 
While the linear parameters, $c_i$, together with the energy spectrum are found by solving eq. \eqref{eq:genEigenProb}, the non-linear parameters, $a_{ij}$ and $s_i$, are found using the Nelder-Mead optimization algorithm. 


\section{Jacobi Coordinates}
It is convenient to use a set a Jacobi coordinates, $\boldsymbol{x} = (\vec{x}_1 , \ldots, \vec{x}_{N-1})^{\mathrm{T}}$, rather than relative distance vectors, $(\vec{r}_i - \vec{r}_j)$ \cite{Varga1995}. The Jacobi coordinates separates then center-of-mass coordinates from the rest, which enables a description of the internal dynamics of the systems. Furthermore, disregarding the center-of-mass coordinates reduces the amount of parameters needed.
Consider the transformation of the coordinate vector, $\boldsymbol{r}$, and its corresponding gradient operator 
\begin{equation}
	\boldsymbol{x} = \mathcal{U} \boldsymbol{r} \quad , \quad \hat{\boldsymbol{\nabla}}_x = \mathcal{U} \hat{\boldsymbol{\nabla}} \; ,
\end{equation}
where $\mathcal{U}$ is the transformation matrix and $\hat{\boldsymbol{\nabla}} = \left( \hat{\nabla}_1 , \ldots , \hat{\nabla}_N \right)^{\mathrm{T}}$. 	
In order to produce Jacobian coordinates, a possible form of the transformation matrix is \cite{Mitroy2013}
\begin{equation}
 \mathcal{U} \: = \: \begin{pmatrix}
1 & -1 & 0 & \hdots & 0 \\
\frac{m_1}{m_1 + m_2} & \frac{m_2}{m_1 + m_2} & -1 & \hdots & 0 \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
\frac{m_1}{m_1 + \ldots + m_N} & \frac{m_2}{m_1  + \ldots + m_N} & \hdots & \hdots & \frac{m_N}{m_1  + \ldots + m_N}
\end{pmatrix} \; .
	\label{eq:JacobiTransMatrix}
\end{equation}
Although this transformation matrix is not unitary, its inverse can be written explicitly \cite{Suzuki1998}.
In general, in the presence of external fields it is not always possible to separate out the contributions from the center-of-mass. However, it is possible to divide the harmonic oscillator operator into an internal (int) and a center-of-mass (CM) part
\begin{equation}
	\hat{T} = \hat{T}^{\mathrm{int}} + \hat{T}^{\mathrm{CM}} \quad , \quad \hat{V}_{\mathrm{HO}} = \hat{V}_{\mathrm{HO}}^{\mathrm{int}} + \hat{V}_{\mathrm{HO}}^{\mathrm{CM}} \; .
\end{equation}
Thus, the total wavefunction of the system can be factorized as  
\begin{equation}
	\Psi \left( \vec{r}_1 , \vec{r}_2 , \ldots , \vec{r}_N \right) = \Phi \left( \vec{x}_1 , \vec{x}_2 , \ldots , \vec{x}_{N-1} \right) \phi( \vec{x}_N ) \; ,
\end{equation}
where the wavefunction dependent on the center-of-mass coordinate, $\vec{x}_N$, can be completely neglected.
Therefore, considering only harmonic confining potentials as external fields, the few-body Hamiltonian considered in Jacobi coordinates reads 
\begin{equation}
	\hat{H} = - \frac{\hbar^2}{2} \hat{\boldsymbol{\nabla}}_{x}^{\mathrm{T}} \Lambda \hat{\boldsymbol{\nabla}}_x + \boldsymbol{x}^{\mathrm{T}} \Omega \boldsymbol{x} + \sum_{i < j}^{N} V_{ij}(\boldsymbol{x}) + \hat{H}^{\mathrm{CM}} \; ,
\end{equation}
where $V_{ij}(\boldsymbol{x})$ is an arbitrary two-body potential. The matrix $\Lambda$ has elements of the form
\begin{equation}
	\Lambda_{kj} = \sum_{i = 1}^{N} \frac{\mathcal{U}_{ki} \mathcal{U}_{ji}}{m_i} \; ,
	\label{eq:LambdaElements}
\end{equation}
which can be derived from the separation of the kinetic operator. The elements \eqref{eq:LambdaElements} are general, however, in the scenario of the transformation matrix being that of eq. \eqref{eq:JacobiTransMatrix}, the elements reduce to $\Lambda_{kj} = \mu_{k}^{-1} \delta_{kj}$, where $\mu_k = \frac{m_{k+1} \left( \sum_{i= 1}^{k} m_{i} \right)}{\sum_{i= 1}^{k+1} m_{i}}$ is the $k$'th reduced mass.
Following this, the elements of the harmonic oscillator matrix $\Omega$ can be written as
\begin{equation}
	\Omega_{kj} = \frac{\hbar^2 \Lambda_{kj} }{2 \;  a_{\mathrm{HO}}^4 } \; ,
\end{equation}
where $a_{\mathrm{HO}}$ is the oscillator length.